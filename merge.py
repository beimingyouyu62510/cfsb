import requests
import yaml
import os
import base64
import json
from hashlib import md5
import sys
import time
import urllib.parse
import asyncio
import aiohttp
from aiohttp import client_exceptions

# ========== é…ç½®ï¼šå¤šä¸ªè®¢é˜…æº ==========
SUBSCRIPTION_URLS = [
    "https://nodesfree.github.io/clashnode/subscribe/clash.yml",
    "https://raw.githubusercontent.com/vxiaov/free_proxies/main/clash/clash.provider.yaml",
    "https://raw.githubusercontent.com/shaoyouvip/free/refs/heads/main/all.yaml",
    "https://raw.githubusercontent.com/peasoft/NoMoreWalls/master/list.yml",
    "https://raw.githubusercontent.com/zhangkaiitugithub/passcro/main/speednodes.yaml",
    "https://raw.githubusercontent.com/xyfqzy/free-nodes/main/nodes/clash.yaml",
    "https://v2rayshare.githubrowcontent.com/2025/08/20250813.yaml",
    "https://raw.githubusercontent.com/go4sharing/sub/main/sub.yaml",
    "https://freenode.openrunner.net/uploads/20250813-clash.yaml",
    "https://raw.githubusercontent.com/ermaozi/get_subscribe/main/subscribe/clash.yml"
]

OUTPUT_ALL = "providers/all.yaml"
OUTPUT_US = "providers/us.yaml"

# æµ‹è¯•é…ç½®
TEST_URL = "http://cp.cloudflare.com/generate_204"
TEST_TIMEOUT = 5  # å•æ¬¡æµ‹é€Ÿè¶…æ—¶æ—¶é—´
MAX_CONCURRENCY = 50  # æœ€å¤§å¹¶å‘æµ‹è¯•æ•°

# ========== ä»£ç†å¤„ç†å‡½æ•° ==========

async def fetch_subscription(session, url):
    """å¼‚æ­¥ä¸‹è½½è®¢é˜…å†…å®¹ï¼Œè®¾ç½®è¶…æ—¶å’ŒçŠ¶æ€ç æ£€æŸ¥"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'
    }
    try:
        async with session.get(url, timeout=15, headers=headers) as resp:
            resp.raise_for_status()
            text = await resp.text()
            return url, text
    except client_exceptions.ClientError as e:
        print(f"[âŒ] ä¸‹è½½å¤±è´¥: {url} é”™è¯¯: {e}", file=sys.stderr)
        return url, None
    except asyncio.TimeoutError:
        print(f"[âŒ] ä¸‹è½½è¶…æ—¶: {url}", file=sys.stderr)
        return url, None

def parse_clash_yaml(text):
    """è§£æ Clash YAML æ ¼å¼çš„è®¢é˜…"""
    try:
        data = yaml.safe_load(text)
        if isinstance(data, dict) and "proxies" in data:
            return data["proxies"]
    except Exception as e:
        print(f"[âš ï¸] è§£æ Clash YAML å¤±è´¥: {e}", file=sys.stderr)
    return None

def parse_base64_links(text):
    """è§£æ Base64 ç¼–ç çš„è®¢é˜…é“¾æ¥ï¼Œæ”¯æŒå¤šç§åè®®"""
    proxies = []
    try:
        text_corrected = text.strip().replace('-', '+').replace('_', '/')
        decoded_text = base64.b64decode(text_corrected + "===").decode("utf-8", errors="ignore")
    except Exception:
        decoded_text = text.strip()
    
    for line in decoded_text.splitlines():
        line = line.strip()
        if not line:
            continue

        try:
            # vmess://
            if line.startswith("vmess://"):
                node_str = base64.b64decode(line[8:] + "===").decode("utf-8")
                node_json = json.loads(node_str)
                proxies.append({
                    "name": node_json.get("ps", "vmess"), "type": "vmess", "server": node_json["add"],
                    "port": int(node_json["port"]), "uuid": node_json["id"], "alterId": int(node_json.get("aid", 0)),
                    "cipher": node_json.get("scy", "auto"), "tls": node_json.get("tls") == "tls",
                    "network": node_json.get("net", "tcp"),
                })
            
            # ss://
            elif line.startswith("ss://"):
                info = line[5:]
                info, *rest = info.split("#", 1)
                name = urllib.parse.unquote(rest[0]) if rest else "ss"
                userinfo_enc, server_port = info.split("@", 1)
                userinfo = base64.b64decode(userinfo_enc + "===").decode(errors="ignore")
                cipher, password = userinfo.split(":", 1)
                server, port = server_port.split(":")
                proxies.append({
                    "name": name, "type": "ss", "server": server,
                    "port": int(port), "cipher": cipher, "password": password,
                })
            
            # trojan://
            elif line.startswith("trojan://"):
                info = line[9:]
                password, rest = info.split("@", 1) if "@" in info else ("", info)
                server_port_raw, *params_raw = rest.split("?", 1)
                server, port = server_port_raw.split(":", 1)
                
                params = urllib.parse.parse_qs(params_raw[0]) if params_raw else {}
                
                proxies.append({
                    "name": params.get("peer", ["trojan"])[0], "type": "trojan", "server": server,
                    "port": int(port), "password": password,
                    "tls": params.get("security", [""])[0] == "tls",
                })
            
            # vless://
            elif line.startswith("vless://"):
                info = line[8:]
                uuid, server_info = info.split("@", 1)
                server_port, *params_raw = server_info.split("?", 1)
                server, port = server_port.split(":", 1)
                
                params = urllib.parse.parse_qs(params_raw[0]) if params_raw else {}
                
                node_config = {
                    "name": params.get("peer", ["vless"])[0],
                    "type": "vless",
                    "server": server,
                    "port": int(port),
                    "uuid": uuid,
                    "network": params.get("type", ["tcp"])[0],
                }

                if node_config["network"] == "ws":
                    ws_opts = {"path": params.get("path", [""])[0]}
                    if "host" in params:
                        ws_opts["headers"] = {"Host": params["host"][0]}
                    node_config["ws-opts"] = ws_opts
                    
                if params.get("security", [""])[0] == "tls":
                    node_config["tls"] = True
                    if "sni" in params:
                        node_config["servername"] = params["sni"][0]
                
                proxies.append(node_config)
            
            # ssr://
            elif line.startswith("ssr://"):
                base64_info = line[6:]
                info = base64.b64decode(base64_info + "===").decode('utf-8')
                
                server, port, protocol, cipher, obfs, password_base64 = info.split(':', 5)
                password, *params_str_list = password_base64.split("/?", 1)
                
                password_decoded = base64.b64decode(password + "===").decode('utf-8')
                
                params = urllib.parse.parse_qs(params_str_list[0]) if params_str_list else {}
                
                proxies.append({
                    'name': params.get('remarks', ['ssr'])[0], 'type': 'ssr', 'server': server,
                    'port': int(port), 'password': password_decoded, 'cipher': cipher, 'protocol': protocol,
                    'obfs': obfs, 'obfs-param': params.get('obfsparam', [''])[0], 'protocol-param': params.get('protoparam', [''])[0]
                })

        except Exception as e:
            print(f"[âš ï¸] è§£æèŠ‚ç‚¹é“¾æ¥å¤±è´¥: {line} é”™è¯¯: {e}", file=sys.stderr)

    return proxies

def deduplicate(proxies):
    """ä½¿ç”¨ md5 å¯¹èŠ‚ç‚¹è¿›è¡Œå»é‡"""
    seen = set()
    result = []
    for p in proxies:
        key_parts = [p.get('server'), str(p.get('port')), p.get('type')]
        if p.get('type') == 'vmess':
            key_parts.append(p.get('uuid'))
        elif p.get('type') in ['ss', 'trojan']:
            key_parts.append(p.get('password'))
        
        key = md5(':'.join(key_parts).encode()).hexdigest()
        if key not in seen:
            seen.add(key)
            result.append(p)
    return result

def filter_us(proxies):
    """æ ¹æ®åç§°è¿‡æ»¤ç¾å›½èŠ‚ç‚¹"""
    us_nodes = [p for p in proxies if "US" in p.get("name", "").upper() or "ç¾å›½" in p.get("name", "")]
    return us_nodes

def save_yaml(path, proxies):
    """å°†ä»£ç†åˆ—è¡¨ä¿å­˜ä¸º YAML æ–‡ä»¶"""
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump({"proxies": proxies}, f, allow_unicode=True)

# ========== å¼‚æ­¥èŠ‚ç‚¹è¿é€šæ€§æµ‹è¯• ==========

async def test_connection_async(session, proxy_config, semaphore):
    """å¼‚æ­¥æµ‹è¯•å•ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ€§"""
    async with semaphore:
        proxy_type = proxy_config.get("type")
        
        # ä»…æ”¯æŒ ss, trojan åè®®æµ‹è¯•ï¼Œå› ä¸º aiohttp ä»£ç†åªæ”¯æŒ http/https
        if proxy_type not in ["ss", "trojan"]:
            return None, None

        proxy_url = f"{proxy_type}://{proxy_config.get('password')}@{proxy_config.get('server')}:{proxy_config.get('port')}"
        
        start_time = time.time()
        try:
            async with session.get(TEST_URL, proxy=proxy_url, timeout=TEST_TIMEOUT, verify_ssl=False) as resp:
                if resp.status == 204:
                    latency = int((time.time() - start_time) * 1000)
                    return proxy_config, latency
                else:
                    return None, None
        except Exception:
            return None, None

# ========== ä¸»è¿è¡Œé€»è¾‘ ==========

async def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«å¼‚æ­¥ä¸‹è½½å’Œæµ‹è¯•æµç¨‹"""
    all_proxies = []
    
    print("--- å¼€å§‹ä¸‹è½½å¹¶åˆå¹¶è®¢é˜… ---")
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_subscription(session, url) for url in SUBSCRIPTION_URLS]
        responses = await asyncio.gather(*tasks)

        for url, text in responses:
            if text:
                proxies = parse_clash_yaml(text) or parse_base64_links(text)
                if proxies:
                    print(f"[âœ…] è®¢é˜…: {url} â†’ {len(proxies)} èŠ‚ç‚¹")
                    all_proxies.extend(proxies)
                else:
                    print(f"[âš ï¸] æœªèƒ½è¯†åˆ«è®¢é˜…æ ¼å¼: {url}", file=sys.stderr)
            else:
                print(f"[âŒ] è·³è¿‡è®¢é˜…: {url}", file=sys.stderr)

    merged = deduplicate(all_proxies)
    print(f"[ğŸ“¦] åˆå¹¶å¹¶å»é‡åèŠ‚ç‚¹æ€»æ•°: {len(merged)}")
    
    us_nodes_to_test = filter_us(merged)
    print(f"[ğŸ”] å·²ç­›é€‰å‡º {len(us_nodes_to_test)} ä¸ª US èŠ‚ç‚¹è¿›è¡Œå¹¶å‘æµ‹è¯•...")

    available_us_nodes = []
    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)
    
    async with aiohttp.ClientSession() as session:
        tasks = [test_connection_async(session, node, semaphore) for node in us_nodes_to_test]
        results = await asyncio.gather(*tasks)

    for node_result, latency in results:
        if node_result:
            node_result['latency'] = latency
            available_us_nodes.append(node_result)

    available_us_nodes.sort(key=lambda x: x['latency'])
    
    print(f"[âœ…] ç»è¿‡æµ‹è¯•ï¼Œè·å¾— {len(available_us_nodes)} ä¸ªå¯ç”¨ US èŠ‚ç‚¹")

    save_yaml(OUTPUT_ALL, merged)
    print(f"[ğŸ’¾] å·²ä¿å­˜æ‰€æœ‰å»é‡èŠ‚ç‚¹åˆ° {OUTPUT_ALL}")

    save_yaml(OUTPUT_US, available_us_nodes[:10])
    print(f"[ğŸ’¾] å·²ä¿å­˜ {len(available_us_nodes[:10])} ä¸ªå¯ç”¨ç¾å›½èŠ‚ç‚¹åˆ° {OUTPUT_US}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nè„šæœ¬å·²æ‰‹åŠ¨åœæ­¢ã€‚")
    except Exception as e:
        print(f"è„šæœ¬è¿è¡Œå‡ºé”™: {e}", file=sys.stderr)
