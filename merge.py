import requests
import yaml
import os
import base64
import json
from hashlib import md5
import sys
import time
import urllib.parse
import asyncio
import aiohttp
import socket
import concurrent.futures
from aiohttp import client_exceptions

# ========== é…ç½®ï¼šå¤šä¸ªè®¢é˜…æº ==========
SUBSCRIPTION_URLS = [
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=www.flashspeed.cloud-ip.cc&type=ws&host=www.flashspeed.cloud-ip.cc&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=speed.gospeedygo.cyou&type=ws&host=speed.gospeedygo.cyou&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=www.1154874.xyz&type=ws&host=www.1154874.xyz&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=cloud.5587124.xyz&type=ws&host=cloud.5587124.xyz&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=blog.1547415.xyz&type=ws&host=blog.1547415.xyz&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=www.zmxquick.cloudns.org&type=ws&host=www.zmxquick.cloudns.org&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=www.vl.de5.net&type=ws&host=www.vl.de5.net&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=www2.zmxquick.cloudns.org&type=ws&host=www2.zmxquick.cloudns.org&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=lovemoneycat.ggff.net&type=ws&host=lovemoneycat.ggff.net&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4",
    "https://gosub.sosorg.nyc.mn/sub?uuid=01991f31-4f11-1c67-b1f4-ff7fab35e816&encryption=none&security=tls&sni=cfvs.eu.org&type=ws&host=cfvs.eu.org&path=%2Fsnippets%3Fip%3Dproxyip%3Aport%28443%29%26nat64%3D6to4"
]
OUTPUT_ALL = "providers/all.yaml"
OUTPUT_US = "providers/us.yaml"

# æµ‹è¯•é…ç½®
TEST_URL = "http://cp.cloudflare.com/generate_204"
TEST_TIMEOUT = 20  # å¢åŠ è¶…æ—¶æ—¶é—´ä»¥æé«˜æˆåŠŸç‡
MAX_CONCURRENCY = 50  # å¹¶å‘æ•°
PING_TIMEOUT = 3  # ping è¶…æ—¶æ—¶é—´ï¼ˆæœªä½¿ç”¨ï¼‰

# ========== ä»£ç†å¤„ç†å‡½æ•° ==========
async def fetch_subscription(session, url):
    """å¼‚æ­¥ä¸‹è½½è®¢é˜…å†…å®¹ï¼Œè®¾ç½®è¶…æ—¶å’ŒçŠ¶æ€ç æ£€æŸ¥"""
    headers = {
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/100.0.4896.127 Safari/537.36'
    }
    try:
        async with session.get(url, timeout=15, headers=headers) as resp:
            resp.raise_for_status()
            text = await resp.text()
            return url, text
    except client_exceptions.ClientError as e:
        print(f"[âŒ] ä¸‹è½½å¤±è´¥: {url} é”™è¯¯: {e}", file=sys.stderr)
        return url, None
    except asyncio.TimeoutError:
        print(f"[âŒ] ä¸‹è½½è¶…æ—¶: {url}", file=sys.stderr)
        return url, None

def parse_clash_yaml(text):
    """è§£æ Clash YAML æ ¼å¼çš„è®¢é˜…"""
    try:
        data = yaml.safe_load(text)
        if isinstance(data, dict) and "proxies" in data:
            return data["proxies"]
    except Exception as e:
        print(f"[âš ï¸] è§£æ Clash YAML å¤±è´¥: {e}", file=sys.stderr)
    return None

def parse_base64_links(text):
    """è§£æ Base64 ç¼–ç çš„è®¢é˜…é“¾æ¥ï¼Œä¸“æ³¨äº vless åè®®ï¼Œä½¿ç”¨åŸå§‹åç§°"""
    proxies = []
    uuid_count = {}  # è·Ÿè¸ª UUID é‡å¤
    seen_names = set()  # è·Ÿè¸ªå·²ä½¿ç”¨åç§°
    try:
        text_corrected = text.strip().replace('-', '+').replace('_', '/')
        decoded_text = base64.b64decode(text_corrected + "===").decode("utf-8", errors="ignore")
    except Exception:
        decoded_text = text.strip()

    for line in decoded_text.splitlines():
        line = line.strip()
        if not line:
            continue
        try:
            if line.startswith("vless://"):
                url_part, *remark_part = line[8:].split("#", 1)
                base_name = urllib.parse.unquote(remark_part[0]) if remark_part else "vless"
                uuid, server_info = url_part.split("@", 1)
                server_port, *params_raw = server_info.split("?", 1)
                server, port = server_port.split(":", 1)
                params = urllib.parse.parse_qs(params_raw[0]) if params_raw else {}
                
                # ä½¿ç”¨åŸå§‹åç§°ï¼Œé™„åŠ  server/port ç¡®ä¿å”¯ä¸€æ€§
                name = base_name
                if name in seen_names:
                    name = f"{base_name}_{server}_{port}"
                seen_names.add(name)
                
                # æ£€æŸ¥ UUID é‡å¤
                uuid_count[uuid] = uuid_count.get(uuid, 0) + 1
                if uuid_count[uuid] > 5:
                    print(f"[âš ï¸] UUID {uuid} é‡å¤ä½¿ç”¨è¶…è¿‡ 5 æ¬¡ï¼Œå¯èƒ½å½±å“èŠ‚ç‚¹å¯ç”¨æ€§", file=sys.stderr)
                
                node_config = {
                    "name": name,
                    "type": "vless",
                    "server": server,
                    "port": int(port),
                    "uuid": uuid,
                    "network": params.get("type", ["tcp"])[0],
                }
                if node_config["network"] == "ws":
                    path = params.get("path", [""])[0]
                    if "proxyip:port(443)" in path:
                        path = path.replace("proxyip:port(443)", f"{server}:{port}")
                    ws_opts = {"path": path}
                    if "host" in params:
                        ws_opts["headers"] = {"Host": params["host"][0]}
                    node_config["ws-opts"] = ws_opts
                if params.get("security", [""])[0] == "tls":
                    node_config["tls"] = True
                    if "sni" in params:
                        node_config["servername"] = params["sni"][0]
                
                proxies.append(node_config)
        except Exception as e:
            print(f"[âš ï¸] è§£æèŠ‚ç‚¹é“¾æ¥å¤±è´¥: {line} é”™è¯¯: {e}", file=sys.stderr)
    return proxies

def deduplicate(proxies):
    """ä½¿ç”¨ md5 å¯¹èŠ‚ç‚¹è¿›è¡Œå»é‡ï¼Œé’ˆå¯¹ vless ä¼˜åŒ–é”®"""
    seen = set()
    result = []
    for p in proxies:
        key_parts = [p.get('server'), str(p.get('port')), p.get('type'), p.get('uuid')]
        if 'ws-opts' in p:
            key_parts.append(p['ws-opts'].get('path', ''))
        key = md5(':'.join(key_parts).encode()).hexdigest()
        if key not in seen:
            seen.add(key)
            result.append(p)
    return result

def filter_us(proxies):
    """æ”¾å®½ç­›é€‰æ¡ä»¶ï¼Œæ•è· US èŠ‚ç‚¹ï¼Œæ’é™¤é US èŠ‚ç‚¹"""
    us_nodes = []
    exclude_keywords = ["HK", "HONG KONG", "é¦™æ¸¯", "SG", "SINGAPORE", "æ–°åŠ å¡", "JP", "JAPAN", "æ—¥æœ¬"]
    for p in proxies:
        name = p.get("name", "").upper()
        if any(keyword in name for keyword in ["US", "USA", "ç¾å›½", "UNITED STATES", "AMERICA"]):
            if not any(exclude in name for exclude in exclude_keywords):
                us_nodes.append(p)
            else:
                print(f"[âš ï¸] æ’é™¤é US èŠ‚ç‚¹: {p['name']}", file=sys.stderr)
    print(f"[ğŸ”] ç­›é€‰å‡º {len(us_nodes)} ä¸ª US èŠ‚ç‚¹: {[p['name'] for p in us_nodes]}")
    return us_nodes

def save_yaml(path, proxies):
    """å°†ä»£ç†åˆ—è¡¨ä¿å­˜ä¸º YAML æ–‡ä»¶"""
    os.makedirs(os.path.dirname(path), exist_ok=True)
    with open(path, "w", encoding="utf-8") as f:
        yaml.safe_dump({"proxies": proxies}, f, allow_unicode=True)

def direct_socket_test(server, port, timeout=TEST_TIMEOUT):
    """ç›´æ¥ä½¿ç”¨ socket æµ‹è¯• TCP è¿æ¥ï¼Œè¿”å›å»¶è¿Ÿ(ms)æˆ– None"""
    try:
        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
        sock.settimeout(timeout)
        start_time = time.time()
        result = sock.connect_ex((server, port))
        end_time = time.time()
        sock.close()
        if result == 0:
            return (end_time - start_time) * 1000
        else:
            return None
    except Exception as e:
        print(f"[âš ï¸] Socket æµ‹è¯•å¤±è´¥: {server}:{port}, é”™è¯¯: {e}", file=sys.stderr)
        return None

async def test_connection_async(session, proxy_config, semaphore):
    """å¼‚æ­¥æµ‹è¯•å•ä¸ªèŠ‚ç‚¹çš„è¿æ¥æ€§ï¼Œé’ˆå¯¹ vless ä¼˜åŒ–ï¼šä»… socket æµ‹è¯•"""
    async with semaphore:
        node_name = proxy_config.get('name', 'æœªçŸ¥èŠ‚ç‚¹')
        server = proxy_config.get('server')
        port = int(proxy_config.get('port', 0))
        if not server or not port:
            print(f"[âŒ] {node_name} | ç¼ºå°‘æœåŠ¡å™¨æˆ–ç«¯å£ä¿¡æ¯", file=sys.stderr)
            return None

        loop = asyncio.get_running_loop()
        socket_latency = await loop.run_in_executor(
            concurrent.futures.ThreadPoolExecutor(),
            direct_socket_test, server, port
        )
        if socket_latency is None:
            print(f"[âŒ] {node_name} | Socket è¿æ¥å¤±è´¥", file=sys.stderr)
            return None

        print(f"[âœ…] {node_name} | vless (Socket: {socket_latency:.0f}ms)")
        return proxy_config

async def main():
    """ä¸»å‡½æ•°ï¼ŒåŒ…å«å¼‚æ­¥ä¸‹è½½å’Œæµ‹è¯•æµç¨‹"""
    all_proxies = []

    print("--- å¼€å§‹ä¸‹è½½å¹¶åˆå¹¶è®¢é˜… ---")
    async with aiohttp.ClientSession() as session:
        tasks = [fetch_subscription(session, url) for url in SUBSCRIPTION_URLS]
        responses = await asyncio.gather(*tasks)
        for url, text in responses:
            if text:
                proxies = parse_clash_yaml(text) or parse_base64_links(text)
                if proxies:
                    print(f"[âœ…] è®¢é˜…: {url} â†’ {len(proxies)} èŠ‚ç‚¹")
                    all_proxies.extend(proxies)
                else:
                    print(f"[âš ï¸] æœªèƒ½è¯†åˆ«è®¢é˜…æ ¼å¼: {url}", file=sys.stderr)
            else:
                print(f"[âŒ] è·³è¿‡è®¢é˜…: {url}", file=sys.stderr)

    merged = deduplicate(all_proxies)
    print(f"[ğŸ“¦] åˆå¹¶å¹¶å»é‡åèŠ‚ç‚¹æ€»æ•°: {len(merged)}")
    print(f"[ğŸ”] æ‰€æœ‰èŠ‚ç‚¹: {[p['name'] for p in merged]}")
    save_yaml(OUTPUT_ALL, merged)
    print(f"[ğŸ’¾] å·²ä¿å­˜æ‰€æœ‰å»é‡èŠ‚ç‚¹åˆ° {OUTPUT_ALL}")

    us_nodes_to_test = filter_us(merged)
    if not us_nodes_to_test:
        print("[âš ï¸] æœªæ‰¾åˆ°ä»»ä½•åç§°åŒ…å« 'US'ã€'USA'ã€'ç¾å›½'ã€'UNITED STATES' æˆ– 'AMERICA' çš„èŠ‚ç‚¹ï¼Œus.yaml æ–‡ä»¶å°†ä¸ºç©ºã€‚")
        return

    available_us_nodes = []
    semaphore = asyncio.Semaphore(MAX_CONCURRENCY)

    async with aiohttp.ClientSession() as session:
        tasks = [test_connection_async(session, node, semaphore) for node in us_nodes_to_test]
        results = await asyncio.gather(*tasks)

    for node_result in results:
        if node_result:
            available_us_nodes.append(node_result)

    available_us_nodes.sort(key=lambda x: x['name'])
    print(f"[âœ…] ç»è¿‡æµ‹è¯•ï¼Œè·å¾— {len(available_us_nodes)} ä¸ªå¯ç”¨ US èŠ‚ç‚¹")
    print(f"[ğŸ”] å¯ç”¨ US èŠ‚ç‚¹: {[node['name'] for node in available_us_nodes]}")
    
    if not available_us_nodes:
        print("[âš ï¸] æ‰€æœ‰ US èŠ‚ç‚¹æµ‹è¯•å¤±è´¥ï¼Œus.yaml å°†ä¸ºç©º")
    else:
        save_yaml(OUTPUT_US, available_us_nodes)
        print(f"[ğŸ’¾] å·²ä¿å­˜ {len(available_us_nodes)} ä¸ªå¯ç”¨ç¾å›½èŠ‚ç‚¹åˆ° {OUTPUT_US}")

if __name__ == "__main__":
    try:
        asyncio.run(main())
    except KeyboardInterrupt:
        print("\nè„šæœ¬å·²æ‰‹åŠ¨åœæ­¢ã€‚")
    except Exception as e:
        print(f"è„šæœ¬è¿è¡Œå‡ºé”™: {e}", file=sys.stderr)
